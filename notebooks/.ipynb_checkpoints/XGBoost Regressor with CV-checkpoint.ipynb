{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os, time, sys\n",
    "\n",
    "from datetime import datetime\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.functions import *\n",
    "\n",
    "# Set the local time zone\n",
    "os.environ['TZ'] = 'America/Montreal'\n",
    "time.tzset()\n",
    "\n",
    "gs_uri = 'gs://videotron-ai-bucket/'\n",
    "dataset_path = gs_uri + 'dataset/'\n",
    "results_path = gs_uri + 'results/'\n",
    "figures_path = gs_uri + 'plots/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from GCP Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe memory usage: 106.62 MB\n"
     ]
    }
   ],
   "source": [
    "CCT_df, perfo_df = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop tickets that are automatically managed per the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCT_df = CCT_df.loc[~CCT_df['Submitter'].str.contains('SYSTEM')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with to many Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe memory usage: 106.36 MB\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.8 # Drop columns with more than 80% of nan values\n",
    "\n",
    "print(\"Dataframe memory usage: %.2f MB\" % (CCT_df.memory_usage().sum()/(1024*1024)))\n",
    "\n",
    "CCT_df = CCT_df.dropna(axis=1, thresh=int(CCT_df.shape[0]*threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast columns to right types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Submit_Date\n",
      "Converting closed_date\n"
     ]
    }
   ],
   "source": [
    "CCT_df = cast_CCT_features(CCT_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# min_dt = tmp_df['closed_date'].min()\n",
    "\n",
    "# tmp_df = tmp_df.loc[tmp_df['closed_date']>min_dt]\n",
    "\n",
    "# days = (tmp_df['closed_date']-tmp_df['Submit_Date']).apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.bar(days.value_counts()[0:20].index, days.value_counts()[0:20].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the data by date and create the label for the prediction\n",
    "* Ticket cnt is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = CCT_df.groupby('Submit_Date_day')\n",
    "\n",
    "agg_df = pd.DataFrame(groupby['status'].count().reset_index().values, columns=['Submit_Date_day', 'Ticket cnt'])\n",
    "agg_df['Ticket cnt'] = agg_df['Ticket cnt'].astype(int)\n",
    "agg_df['Submit_Date_day'] = pd.to_datetime(agg_df['Submit_Date_day'])\n",
    "agg_df['year-month'] = agg_df['Submit_Date_day'].apply(lambda x: str(x.year) + '-'+ str(x.month))\n",
    "min_dt = agg_df['Submit_Date_day'] .min()\n",
    "max_dt = agg_df['Submit_Date_day'] .max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some charts for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(agg_df['Submit_Date_day'].values, agg_df['Ticket cnt'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Time Series #1: Date-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_date_related_features(agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Time Series #2: Event-Related Features\n",
    "Here is a list of important events that videotron wants to integrate to the machine learning model:\n",
    "* Black Friday: not a fixed date\n",
    "* Cyber Monday: not a fixed date (the next monday after a black friday)\n",
    "* Back to school: not a fixed date. From mid August until mid-september: we chose the last monday of august as a generic date for back to school\n",
    "* Moving period: from mid-may until mid-july. There is a surge at the end of june. Most of the lease agreement in Quebec start July 1st\n",
    "* Holidays promotions: from mid-november until the holidays: 2 events: Christmas (December 25th) and first day of the year (January 1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_event_related_features(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Time Series #3: Lag Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ACF (Autocorrelation Function) and PACF (Partial Autocorrelation Function) plots to determine the lag at which the correlation is significant\n",
    "\n",
    "* ACF: The ACF plot is a measure of the correlation between the time series and the lagged version of itself\n",
    "* PACF: The PACF plot is a measure of the correlation between the time series with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons\n",
    "\n",
    "More details on ACF and PACF: https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(dataset['Ticket cnt'], lags=30)\n",
    "plot_pacf(dataset['Ticket cnt'], lags=30) \n",
    "\n",
    "# Build the lag features\n",
    "dataset = build_lag_features(dataset, 'Ticket cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Time Series #4: MEP (IT events planning) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mep_df = build_mep_features(dataset_path)\n",
    "dataset = dataset.merge(mep_df, how='left', left_on='Submit_Date_day', right_on='mep_date_day').drop(columns=['mep_date_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Time Series #5: performances features for Videotron's call center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfo_df = build_perfo_features(dataset_path)\n",
    "# perfo_df = perfo_df.loc[perfo_df['Date']>=min_dt].reset_index(drop=True).drop(columns=['Date'])\n",
    "# dataset = pd.concat([dataset, perfo_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering #6: Weather related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df = build_weather_features(dataset_path, min_dt, max_dt, plot=False)\n",
    "# dataset = pd.concat([dataset, weather_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering #7: STM related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering #8: Google Trends related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trends_df = pd.read_csv(dataset_path + 'keyword_trends_dataset.csv', low_memory=False)\n",
    "# trends_df['date'] = pd.to_datetime(trends_df['date'].fillna('1900-01-01 00:00:00.000'))\n",
    "# trends_df = trends_df.loc[trends_df['date']>=min_dt].reset_index(drop=True).drop(columns=['date'])\n",
    "# kw_list = trends_df.columns.values\n",
    "# dataset = pd.concat([dataset, trends_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering #9: Feature selection\n",
    "Based on the following article: https://machinelearningmastery.com/feature-selection-time-series-forecasting-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.drop(columns=['Submit_Date_day', 'year-month'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df)\n",
    "df = pd.DataFrame(scaler.transform(df), columns=df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation: analysis\n",
    "* Pearson correlation: https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9\n",
    "* How to interpret Pearson correlation: https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/correlation/interpret-the-results/\n",
    "\n",
    "Only values with a p-value less or equal than ⍺ (⍺=0.05) and a high pearson-r (above ≈0.40 or below ≈-0.40) score should be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corrmat = df.corr(method='pearson', min_periods=500)\n",
    "\n",
    "# plot absolute values\n",
    "corrmat = np.abs(corrmat)\n",
    "sns.set(context=\"paper\", font=\"monospace\")\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, cmap=\"YlGnBu\", vmin=0, vmax=1,square=True, xticklabels = False, yticklabels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat['Ticket cnt'].reset_index()[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the correlation between the features and the target ticket cnt\n",
    "Use a rolling window to display the synchrony pattern between the target time serie and the feature time serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "person_r_threshold = 0.40\n",
    "\n",
    "# Look for correlation between the ticket cnt and the MEP planning\n",
    "# corr_df = plot_pearson_corr(df, mep_df.iloc[:, 1:].columns.values, plot=True, threshold=person_r_threshold, alpha=alpha)\n",
    "corr_df = plot_pearson_corr(df, df.drop(columns=['Ticket cnt']).columns.values, plot=True, threshold=person_r_threshold, alpha=alpha)\n",
    "\n",
    "# Compute the pearson coefficient correlation and display only the most significant features\n",
    "drop_list = corr_df.loc[~((corr_df['abs_pearson_r'] > person_r_threshold) & (corr_df['p-value'] < alpha)), 'feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_num = 50\n",
    "width = 0.9\n",
    "\n",
    "\n",
    "x = corr_df.tail(remain_num)['abs_pearson_r'].values\n",
    "y = corr_df.tail(remain_num)['feature'].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,18))\n",
    "rects = ax.barh(y, x, color='r')\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(y, rotation='horizontal')\n",
    "ax.set_xlabel(\"absolute corr\", fontsize = 14)\n",
    "ax.set_title(\"Correlations between features and Ticket cnt\", fontsize = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the feature engineered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={'Submit_Date_day':'date'}).dropna(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(dataset_path + 'videotron_full_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a first model to validate the feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day Forward-chaining Nested Cross-Validation\n",
    "Technic explained here: https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*2-zaRQ-dsv8KWxOlzc8VaA.png\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters for the model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 26\n",
    "n_iter = 100\n",
    "val_length = 1 # in months\n",
    "test_length = 3 # in months\n",
    "\n",
    "xgb_imp_threshold = 0 #0.005\n",
    "alpha = 0.05\n",
    "person_r_threshold = 0.20\n",
    "\n",
    "train_start_dt = dataset['date'].min()\n",
    "\n",
    "xgb_params = {    \n",
    "              'objective':'reg:squarederror',\n",
    "              'random_state': 42,\n",
    "              'n_jobs': -1\n",
    "             }\n",
    "\n",
    "param_dist = {\n",
    "              'n_estimators': stats.randint(100, 1000),\n",
    "              'learning_rate': stats.loguniform(0.01, 0.1),\n",
    "              'subsample': stats.uniform(0.3, 0.7),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "              'min_child_weight': [1, 2, 3, 4, 5],\n",
    "              'random_state': [42]\n",
    "             }\n",
    "\n",
    "xgb_rg = xgb.XGBRegressor(**xgb_params)\n",
    "estimators = []\n",
    "predictions = []\n",
    "\n",
    "range_ = range(24, n_folds+1)\n",
    "\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "r2_scores =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model training\n",
    "Apply a feature selection during the model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for offset_months in range_:\n",
    "    print('Outer loop %d' % offset_months)\n",
    "    index_val = offset_months-1\n",
    "    \n",
    "    X_train, X_val, X_test, X_out_of_time, y_train, y_val, y_test, y_out_of_time, labels = get_train_val_test_dataset(dataset, \n",
    "                                                                                                              train_start_dt,\n",
    "                                                                                                              val_length,\n",
    "                                                                                                              test_length,\n",
    "                                                                                                              offset_months)\n",
    "    \n",
    "\n",
    "    # Standardize the train, validation and test set based on the train data set\n",
    "    # Not required for XGBoost or tree based algo but mandatory for other classifier\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train       = pd.DataFrame(scaler.transform(X_train),       index=X_train.index,       columns=X_train.columns.values)\n",
    "    X_val         = pd.DataFrame(scaler.transform(X_val),         index=X_val.index,         columns=X_train.columns.values)\n",
    "    X_test        = pd.DataFrame(scaler.transform(X_test),        index=X_test.index,        columns=X_train.columns.values)\n",
    "    if X_out_of_time.shape[0] > 0:\n",
    "        X_out_of_time = pd.DataFrame(scaler.transform(X_out_of_time), index=X_out_of_time.index, columns=X_train.columns.values)\n",
    "        \n",
    "    # Plot the train, validation and test set\n",
    "    if (offset_months <= n_folds):\n",
    "        plot_train_val_test(dataset['date'], labels, X_train.index, X_val.index, X_test.index, X_out_of_time.index)\n",
    "\n",
    "    f_list = apply_feature_selection(X_train, feature_selection=False, xgb_imp_threshold=xgb_imp_threshold, person_r_threshold=person_r_threshold)\n",
    "    \n",
    "    # Create a new pipeline for a randomized search CV\n",
    "    regressor = RandomizedSearchCV(xgb_rg, cv=[(X_train[f_list].index,\n",
    "                                                X_val[f_list].index)],\n",
    "                                   param_distributions=param_dist, \n",
    "                                   n_iter=n_iter, scoring = 'neg_mean_squared_error', \n",
    "                                   error_score=0, verbose=3, n_jobs=-1)\n",
    "    \n",
    "    # The cross validation will be done only once on the train and validation set\n",
    "    regressor.fit(X_train[f_list].append(X_val[f_list]), y_train.append(y_val))    \n",
    "    \n",
    "    # Get the best estimator\n",
    "    xgb_rg = regressor.best_estimator_\n",
    "    \n",
    "    # Fit a new regressor on the best estimator parameters and evaluate the model\n",
    "    # The model is fitted on the train & validation dateset then evaluated on the test set\n",
    "    xgb_rg.fit(X_train[f_list].append(X_val[f_list]), y_train.append(y_val))    \n",
    "    estimators.append(xgb_rg)\n",
    "    y_pred = xgb_rg.predict(X_test[f_list])\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    print('MSE loop %d: %f' % (offset_months, mse_scores[-1]))\n",
    "    print('RMSE loop %d: %f' % (offset_months, rmse_scores[-1]))\n",
    "    print('R2 loop %d: %f' % (offset_months, r2_scores[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = np.mean(mse_scores) \n",
    "rmse_score = np.mean(rmse_scores) \n",
    "r2 = np.mean(r2_scores) \n",
    "\n",
    "print('MSE score on nested cross-validation: %f' % mse_score)\n",
    "print('RMSE score on nested cross-validation: %f' % rmse_score)\n",
    "print('R2 score on nested cross-validation: %f' % r2)\n",
    "\n",
    "print('MSE score of the last model: %f' % mse_scores[-1])\n",
    "print('RMSE score of the last model: %f' % rmse_scores[-1])\n",
    "print('R2 score of the last model: %f' % r2_scores[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the final model and the final predictions from the nested cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rg = estimators[-1]\n",
    "y_pred = predictions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display feature importance\n",
    "The most important features are showed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = len(xgb_rg.feature_importances_)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, int(nb_features/3)))\n",
    "\n",
    "xgb.plot_importance(xgb_rg, importance_type='gain', height=0.3, ax=ax,\n",
    "                    title='XGBoost Regressor Feature Importance', color='green',\n",
    "                    ylabel='Feature name', xlabel='Feature importance (Gain)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the regression's metrics\n",
    "* RMSE\n",
    "* MSE\n",
    "* R<sup>2</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = np.mean(mse_scores) \n",
    "rmse_score = np.mean(rmse_scores) \n",
    "r2 = np.mean(r2_scores) \n",
    "\n",
    "print('MSE score on nested cross-validation: %f' % mse_score)\n",
    "print('RMSE score on nested cross-validation: %f' % rmse_score)\n",
    "print('R2 score on nested cross-validation: %f' % r2)\n",
    "\n",
    "print('MSE score of the last model: %f' % mse_scores[-1])\n",
    "print('RMSE score of the last model: %f' % rmse_scores[-1])\n",
    "print('R2 score of the last model: %f' % r2_scores[-1])\n",
    "\n",
    "# We should keep only the last model trained during the nest cross-validation. Save the results of this model\n",
    "results={'Datetime': dt.datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "         'MSE': mse_score,\n",
    "         'RMSE': rmse_score,\n",
    "         'R2': r2,\n",
    "         'model': 'XGBoost Regressor',\n",
    "         'comments': 'XGBoost Regressor with internal + MEP features'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append the metrics to the results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = export_results(results, path=results_path)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predicted volume of tickets vs the observation\n",
    "The prediction is made on the last test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, test_start_dt, test_end_dt = compute_train_val_test_dates(train_start_dt, val_length, test_length, n_folds)\n",
    "\n",
    "plot_predictions_vs_observations(dataset.loc[X_test.index, 'date'].values, y_test, y_pred, test_start_dt, test_end_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the predictions on 3 months of test for ROI computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_str = datetime.now().strftime('%Y%m%d%H%M')\n",
    "\n",
    "output_df = pd.DataFrame(dataset.loc[X_test.index, 'date'].values, columns=['date'])\n",
    "output_df['ticket cnt obs'] = y_test\n",
    "output_df['ticket cnt pred'] = y_pred\n",
    "\n",
    "output_df.to_csv(results_path + f'ticket_count_prediction_{dt_str}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
